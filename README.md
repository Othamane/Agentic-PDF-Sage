# ğŸ¤– PDF Sage - Intelligent Document Chat System

**Production-ready RAG chatbot with enhanced AI reasoning - Powered by Gemini**

## ğŸ¯ What's Included

âœ… **Complete Backend** (FastAPI + PostgreSQL)
âœ… **Complete Frontend** (React + Modern UI)
âœ… **Gemini LLM Integration** (Fast & Reliable)
âœ… **Enhanced Vector Search** (FAISS + Sentence Transformers)
âœ… **Production Docker Setup**
âœ… **Security & Monitoring**
âœ… **Status Management & Debugging**

## ğŸš€ Quick Start (5 Minutes)

### 1. Prerequisites
- Docker & Docker Compose
- 8GB+ RAM (16GB recommended)
- 10GB+ free disk space
- Gemini API Key (free from Google AI Studio)

### 2. Clone & Setup
```bash
git clone <your-repository>
cd pdf-sage

# Copy environment template
cp .env.production.template .env.production
```

### 3. Configure Environment
Edit `.env.production` - **Add your Gemini API key for best performance**
```bash
# Required: Basic security
DB_PASSWORD=your_secure_password_123
SECRET_KEY=your-super-secret-key-change-this-in-production

# RECOMMENDED: Gemini API (fast, reliable, high-quality)
GEMINI_API_KEY=your_gemini_api_key_here
LLM_PROVIDER=gemini
LLM_MODEL=gemini-2.5-flash

# Alternative: Free local LLM (slower but no API costs)
# LLM_PROVIDER=ollama
# LLM_MODEL=llama2

# Optional: Production domain
ALLOWED_HOSTS='["yourdomain.com","localhost"]'
```

### 4. Get Gemini API Key (Free)
```bash
# Visit: https://aistudio.google.com/app/apikey
# Create free account
# Generate API key
# Add to .env.production as GEMINI_API_KEY
```

### 5. Launch Application
```bash
# Start all services
docker-compose up --build

# If using Ollama fallback: Wait for models to download (~5-10 minutes)
# Monitor progress: docker-compose logs -f ollama-init
```

### 6. Access Application
- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/api/chat/status

## ğŸ“ Enhanced Project Structure
```
pdf-sage/
â”œâ”€â”€ backend/                           # FastAPI Backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/v1/endpoints/         # Enhanced API Endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ enhanced_chat_endpoints.py    # âœ… Chat with Gemini
â”‚   â”‚   â”‚   â”œâ”€â”€ enhanced_document_endpoints.py # âœ… Document management
â”‚   â”‚   â”‚   â””â”€â”€ health.py                     # âœ… Health checks
â”‚   â”‚   â”œâ”€â”€ core/                    # Core Configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py            # âœ… Enhanced settings
â”‚   â”‚   â”‚   â”œâ”€â”€ database.py          # âœ… PostgreSQL + async
â”‚   â”‚   â”‚   â””â”€â”€ logging_config.py    # âœ… Structured logging
â”‚   â”‚   â”œâ”€â”€ models/                  # Database Models
â”‚   â”‚   â”‚   â”œâ”€â”€ conversation.py      # âœ… Chat conversations
â”‚   â”‚   â”‚   â”œâ”€â”€ document.py          # âœ… Document metadata
â”‚   â”‚   â”‚   â”œâ”€â”€ agent_step.py        # âœ… Reasoning steps
â”‚   â”‚   â”‚   â””â”€â”€ retrieval_log.py     # âœ… Source tracking
â”‚   â”‚   â”œâ”€â”€ services/                # Enhanced Business Logic
â”‚   â”‚   â”‚   â”œâ”€â”€ gemini_llm_service.py        # âœ… Gemini + HF fallback
â”‚   â”‚   â”‚   â”œâ”€â”€ enhanced_agent_service.py    # âœ… Advanced reasoning
â”‚   â”‚   â”‚   â”œâ”€â”€ enhanced_document_service.py # âœ… Status management
â”‚   â”‚   â”‚   â””â”€â”€ enhanced_vector_service.py   # âœ… Improved search
â”‚   â”‚   â””â”€â”€ main.py                  # âœ… FastAPI app
â”‚   â”œâ”€â”€ db/init.sql                  # âœ… Database schema
â”‚   â”œâ”€â”€ requirements.txt             # âœ… Dependencies with Gemini
â”‚   â””â”€â”€ Dockerfile                   # âœ… Production container
â”œâ”€â”€ frontend/                        # React Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/              # React Components
â”‚   â”‚   â”‚   â”œâ”€â”€ Chat/               # Enhanced Chat Interface
â”‚   â”‚   â”‚   â”œâ”€â”€ Documents/          # Document Management
â”‚   â”‚   â”‚   â”œâ”€â”€ Layout/             # App Layout
â”‚   â”‚   â”‚   â””â”€â”€ UI/                 # Reusable Components
â”‚   â”‚   â”œâ”€â”€ pages/                  # Page Components
â”‚   â”‚   â”œâ”€â”€ services/               # API Services
â”‚   â”‚   â””â”€â”€ styles/                 # Modern CSS
â”‚   â”œâ”€â”€ package.json                # âœ… Dependencies
â”‚   â””â”€â”€ Dockerfile                  # âœ… Production container
â”œâ”€â”€ docker-compose.yml              # âœ… Full stack orchestration
â”œâ”€â”€ .env.production.template        # âœ… Environment template
â””â”€â”€ README.md                       # âœ… This complete guide
```

## ğŸ¯ Enhanced Features

### ğŸ¤– **Advanced AI Reasoning**
- âœ… **Gemini 2.5 Flash** - Latest Google AI model (fast, accurate)
- âœ… **Multi-step reasoning** (Planning â†’ Retrieval â†’ Synthesis â†’ Validation)
- âœ… **Transparent reasoning traces**
- âœ… **Automatic fallback** to local models if needed
- âœ… **Enhanced error handling** & recovery

### ğŸ” **Intelligent Document Processing**
- âœ… **PDF upload & text extraction**
- âœ… **Advanced chunking & embeddings**
- âœ… **Enhanced vector similarity search** (FAISS)
- âœ… **Source citation & tracking**
- âœ… **Status consistency** across page reloads

### ğŸ’¬ **Modern Chat Interface**
- âœ… **Real-time reasoning display**
- âœ… **Source citations with relevance scores**
- âœ… **Document selection & management**
- âœ… **Conversation history**
- âœ… **Enhanced debugging** information

### ğŸ“Š **Analytics & Monitoring**
- âœ… **System health monitoring**
- âœ… **Document processing stats**
- âœ… **Performance metrics**
- âœ… **Enhanced error tracking**
- âœ… **Debug endpoints** for troubleshooting

### ğŸ”’ **Production Security**
- âœ… **Rate limiting** (per IP)
- âœ… **Security headers** (CSP, HSTS, etc.)
- âœ… **Input validation & sanitization**
- âœ… **CORS protection**
- âœ… **Non-root containers**

### âš¡ **Performance Stack**
- âœ… **Gemini API** - 10x faster than local models
- âœ… **Enhanced vector search** - Better chunk retrieval
- âœ… **Async processing** - Non-blocking operations
- âœ… **Database optimization** - Connection pooling
- âœ… **Smart caching** - Reduced API calls

## ğŸ› ï¸ Using PDF Sage

### 1. Upload Documents
```bash
# Access document manager
http://localhost:3000/documents

# Upload PDF files via web interface
# Monitor processing status in real-time
# Files are automatically processed and vectorized
```

### 2. Start Intelligent Conversations
```bash
# Access chat interface
http://localhost:3000/chat

# Select documents to chat with
# Ask complex questions
# See detailed reasoning traces
# Review source citations
```

### 3. Monitor System Health
```bash
# Check system status
curl http://localhost:8000/api/chat/status

# Debug document processing
http://localhost:8000/api/debug/document/{document_id}

# Test vector search
http://localhost:8000/api/debug/vector-search
```

## ğŸ”§ Configuration Options

### **LLM Providers (in order of recommendation)**

1. **Gemini (Recommended)**
```bash
   LLM_PROVIDER=gemini
   LLM_MODEL=gemini-2.5-flash
   GEMINI_API_KEY=your_key_here
```
   - âœ… Fastest responses (2-5 seconds)
   - âœ… Highest quality reasoning
   - âœ… Most reliable
   - ğŸ’° Generous free tier

2. **Ollama (Free Local)**
```bash
   LLM_PROVIDER=ollama
   LLM_MODEL=llama2
```
   - âœ… Completely free
   - âš ï¸ Slower responses (15-60 seconds)
   - âš ï¸ Requires more RAM

3. **HuggingFace (Fallback)**
```bash
   LLM_PROVIDER=huggingface
```
   - âœ… Free
   - âš ï¸ Limited model options

### **System Scaling**
```bash
# For high-traffic production
RATE_LIMIT_REQUESTS=1000
DATABASE_POOL_SIZE=20
VECTOR_CACHE_SIZE=100

# For development
DEBUG=true
ENABLE_VECTOR_DEBUG=true
ENABLE_LLM_DEBUG=true
```

## ğŸ¯ Expected Performance

| Configuration | Response Time | Quality | Cost |
|---------------|---------------|---------|------|
| **Gemini 2.5 Flash** | 2-5 seconds | Excellent | Free tier + usage |
| **Ollama Local** | 15-60 seconds | Good | Completely free |
| **HuggingFace** | 10-30 seconds | Fair | Free |

## ğŸ†˜ Troubleshooting

### Common Issues & Solutions

#### 1. **"No LLM providers available"**
- âœ… Check `GEMINI_API_KEY` in `.env.production`
- âœ… Verify API key at https://aistudio.google.com/app/apikey
- âœ… Check backend logs: `docker-compose logs backend`

#### 2. **"No chunks found in similarity search"**
- âœ… Ensure documents are fully processed (status: "processed")
- âœ… Check vector store: `http://localhost:8000/api/debug/document/{id}`
- âœ… Re-upload document if processing failed

#### 3. **Slow response times**
- âœ… Switch to Gemini: Set `LLM_PROVIDER=gemini`
- âœ… Check system resources
- âœ… Monitor logs for timeouts

### **Debug Endpoints**
- `/api/chat/status` - System health
- `/api/debug/document/{id}` - Document status
- `/api/debug/vector-search` - Test search

### **Getting Help**
- Check logs: `docker-compose logs -f`
- API documentation: http://localhost:8000/docs
- Health status: http://localhost:8000/api/chat/status

---

**PDF Sage** - Transform your PDFs into intelligent conversations powered by advanced AI reasoning.